{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch>=1.8,<1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightning-fabric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = psutil.Process()\n",
    "cpu_start = process.cpu_percent()\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217a4d01fea24ec6855004363719baff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "\n",
    "with ProgressHook() as hook:\n",
    "\n",
    "\n",
    "    diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "\n",
    "output_dir = \"diarization_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "rttm_path = os.path.join(output_dir, \"audio.rttm\")\n",
    "\n",
    "with open(rttm_path, \"w\") as rttm_file:\n",
    "    diarization.write_rttm(rttm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.566001427173614"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = time.time()\n",
    "cpu_end = process.cpu_percent()\n",
    "latency = end - start\n",
    "cpu_usage = cpu_end - cpu_start\n",
    "\n",
    "\n",
    "latency / 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type Source  ID  Start_Time  Duration  Other1  Other2     Speaker  \\\n",
      "0  SPEAKER  audio   1       1.381     2.177     NaN     NaN  SPEAKER_01   \n",
      "1  SPEAKER  audio   1       4.790     1.603     NaN     NaN  SPEAKER_01   \n",
      "2  SPEAKER  audio   1       7.287     0.675     NaN     NaN  SPEAKER_01   \n",
      "3  SPEAKER  audio   1       9.127     3.578     NaN     NaN  SPEAKER_01   \n",
      "4  SPEAKER  audio   1      12.873     2.059     NaN     NaN  SPEAKER_01   \n",
      "\n",
      "   Other3  Other4  \n",
      "0     NaN     NaN  \n",
      "1     NaN     NaN  \n",
      "2     NaN     NaN  \n",
      "3     NaN     NaN  \n",
      "4     NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./diarization_output/audio.rttm', delimiter=r'\\s+', header=None)\n",
    "\n",
    "data.columns = [\"Type\", \"Source\", \"ID\", \"Start_Time\", \"Duration\",  \n",
    "                \"Other1\", \"Other2\", \"Speaker\", \"Other3\", \"Other4\"]\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "speaker_segments = defaultdict(list)  # Map<Speaker, List<Segment>>\n",
    "\n",
    "def split_audio_by_speaker(audio, df, min_duration_sec=4):\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        speaker = row['Speaker']\n",
    "        start_ms = row['Start_Time'] * 1000  \n",
    "        duration_ms = row['Duration'] * 1000  \n",
    "        \n",
    "        if duration_ms >= min_duration_sec * 1000:  \n",
    "            segment = audio[start_ms:start_ms + duration_ms]\n",
    "            \n",
    "            speaker_segments[speaker].append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_file(\"./audio.wav\")\n",
    "\n",
    "split_audio_by_speaker(audio, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported SPEAKER_01_segment_1.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_2.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_3.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_4.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_5.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_6.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_7.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_8.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_9.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_10.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_11.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_12.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_13.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_14.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_15.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_16.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_17.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_18.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_19.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_20.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_21.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_22.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_23.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_24.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_25.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_26.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_27.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_28.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_29.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_30.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_31.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_32.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_33.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_34.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_35.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_36.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_37.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_38.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_39.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_40.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_41.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_42.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_43.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_44.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_45.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_46.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_47.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_48.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_49.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_50.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_51.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_52.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_53.wav to diarization_output\n",
      "Exported SPEAKER_01_segment_54.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_1.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_2.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_3.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_4.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_5.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_6.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_7.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_8.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_9.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_10.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_11.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_12.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_13.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_14.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_15.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_16.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_17.wav to diarization_output\n",
      "Exported SPEAKER_00_segment_18.wav to diarization_output\n",
      "Audio segments saved in the 'diarization_output' directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for speaker, segments in speaker_segments.items():\n",
    "    for i, segment in enumerate(segments):\n",
    "        segment.export(os.path.join(output_dir, f\"{speaker}_segment_{i+1}.wav\"), format=\"wav\")\n",
    "        print(f\"Exported {speaker}_segment_{i+1}.wav to {output_dir}\")\n",
    "\n",
    "print(f\"Audio segments saved in the '{output_dir}' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
